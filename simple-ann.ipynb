{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple-ann\n",
    "\n",
    "Use the \"Run\" button to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.weights = np.array([np.random.randn(), np.random.randn()])\n",
    "        self.bias = np.random.randn()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_deriv(self, x):\n",
    "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
    "        layer_2 = self._sigmoid(layer_1)\n",
    "        prediction = layer_2\n",
    "        return prediction\n",
    "\n",
    "    def _compute_gradients(self, input_vector, target):\n",
    "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
    "        layer_2 = self._sigmoid(layer_1)\n",
    "        prediction = layer_2\n",
    "\n",
    "        derror_dprediction = 2 * (prediction - target)\n",
    "        dprediction_dlayer1 = self._sigmoid_deriv(layer_1)\n",
    "        dlayer1_dbias = 1\n",
    "        dlayer1_dweights = (0 * self.weights) + (1 * input_vector)\n",
    "\n",
    "        derror_dbias = (\n",
    "            derror_dprediction * dprediction_dlayer1 * dlayer1_dbias\n",
    "        )\n",
    "        derror_dweights = (\n",
    "            derror_dprediction * dprediction_dlayer1 * dlayer1_dweights\n",
    "        )\n",
    "\n",
    "        return derror_dbias, derror_dweights\n",
    "\n",
    "    def _update_parameters(self, derror_dbias, derror_dweights):\n",
    "        self.bias = self.bias - (derror_dbias * self.learning_rate)\n",
    "        self.weights = self.weights - (derror_dweights * self.learning_rate)\n",
    "\n",
    "    def train(self, input_vectors, targets, iterations):\n",
    "\n",
    "        cumulative_errors = []\n",
    "\n",
    "        for current_iteration in range(iterations):\n",
    "\n",
    "            # Pick a data instance at random\n",
    "\n",
    "            random_data_index = np.random.randint(len(input_vectors))\n",
    "\n",
    "            input_vector = input_vectors[random_data_index]\n",
    "\n",
    "            target = targets[random_data_index]\n",
    "\n",
    "            # Compute the gradients and update the weights\n",
    "\n",
    "            derror_dbias, derror_dweights = self._compute_gradients(\n",
    "\n",
    "                input_vector, target\n",
    "\n",
    "            )\n",
    "\n",
    "            self._update_parameters(derror_dbias, derror_dweights)\n",
    "\n",
    "            # Measure the cumulative error for all the instances\n",
    "\n",
    "            if current_iteration % 100 == 0:\n",
    "\n",
    "                cumulative_error = 0\n",
    "\n",
    "                # Loop through all the instances to measure the error\n",
    "\n",
    "                for data_instance_index in range(len(input_vectors)):\n",
    "\n",
    "                    data_point = input_vectors[data_instance_index]\n",
    "\n",
    "                    target = targets[data_instance_index]\n",
    "\n",
    "                    prediction = self.predict(data_point)\n",
    "\n",
    "                    error = np.square(prediction - target)\n",
    "\n",
    "                    cumulative_error = cumulative_error + error\n",
    "\n",
    "                cumulative_errors.append(cumulative_error)\n",
    "\n",
    "        return cumulative_errors\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"marke a prediction!\")\n",
    "    learning_rate = 0.1\n",
    "    input_vectors = np.array(\n",
    "        [[3, 1.5], [2, 1],\n",
    "            [4, 1.5],\n",
    "            [3, 4],\n",
    "            [3.5, 0.5],\n",
    "            [2, 0.5],\n",
    "            [5.5, 1],\n",
    "            [1, 1],\n",
    "         ]\n",
    "    )\n",
    "    targets = np.array([0, 1, 0, 1, 0, 1, 1, 0])\n",
    "    input_vector = input_vectors[0]\n",
    "    neural_network = NeuralNetwork(learning_rate)\n",
    "    prediction = neural_network.predict(input_vector)\n",
    "    print(f\"The prediction result is: {prediction}\")\n",
    "    training_error = neural_network.train(input_vectors, targets, 10000)\n",
    "    plt.plot(training_error)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Error for all training instances\")\n",
    "    plt.savefig(\"cumulative_error.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"simple-ann\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
